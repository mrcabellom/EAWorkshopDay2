{
  "cells": [
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "## Cognitive Services"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "### ConfiguraciÃ³n Inicial\n",
        "\n",
        "Primero, configuraremos todas las urls y las claves necesarias para ejecutar los distintos servicios cognitivos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cs_key = \"911e9745a6604f088c56ea1b9cb02c87\"\n",
        "cs_base_url = \"https://westeurope.api.cognitive.microsoft.com/\"\n",
        "bs_account_name = \"eatraining3939401398\"\n",
        "translate_url = \"https://api.cognitive.microsofttranslator.com/translate?api-version=3.0\"\n",
        "translate_key = \"aeac4c9876ee48b1b7c9adde6f5537fd\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "class CognitiveServices():\n",
        "    def __init__(self, base_url, api_key, translate_url):\n",
        "        self.__api_key = api_key\n",
        "        self.__base_url = base_url\n",
        "        self.__api_version = \"v2.0\"\n",
        "        self.__translate_url = translate_url\n",
        "        self.__init_config()\n",
        "        \n",
        "    def __init_config(self):\n",
        "        \n",
        "        self.__headers = {'Ocp-Apim-Subscription-Key': self.__api_key }\n",
        "        self.__custom_vision_url = f\"{self.__base_url}vision/{self.__api_version}/\"\n",
        "        self.__text_anaytics_url = f\"{self.__base_url}text/analytics/{self.__api_version}/\"\n",
        "    \n",
        "    def computer_vision_api(self, blob_url):\n",
        "        vision_analyze_url = self.__custom_vision_url + \"analyze\"\n",
        "        params   = {'visualFeatures': 'Faces,Tags,Categories,Description,Color'}\n",
        "        data     = {'url': blob_url}\n",
        "        response = requests.post(vision_analyze_url, headers= self.__headers, params=params, json=data)\n",
        "        response.raise_for_status()\n",
        "        analysis = response.json()\n",
        "        return analysis\n",
        "    \n",
        "    def ocr(self, blob_url, filename, draw_image=False):\n",
        "        ocr_url = self.__custom_vision_url + \"ocr\"\n",
        "        params   = {'language': 'unk', 'detectOrientation ': 'true'}\n",
        "        data     = {'url': blob_url}\n",
        "        response = requests.post(ocr_url, headers=self.__headers, params=params, json=data)\n",
        "        response.raise_for_status()\n",
        "        analysis = response.json()\n",
        "        line_infos = [region[\"lines\"] for region in analysis[\"regions\"]]\n",
        "        word_infos = self.extract_boundings(line_infos)\n",
        "        if draw_image:\n",
        "            self.draw_bounding_boxes(word_infos, blob_url, filename)\n",
        "        text = self.extract_text_from_ocr(line_infos)\n",
        "        return \" \".join(text), word_infos\n",
        "    \n",
        "    def extract_boundings(self, line_infos):\n",
        "        word_infos = []\n",
        "        for line in line_infos:\n",
        "            for word_metadata in line:\n",
        "                for word_info in word_metadata[\"words\"]:\n",
        "                    word_infos.append(word_info)\n",
        "        return word_infos\n",
        "    \n",
        "    def extract_text_from_ocr(self, line_infos):\n",
        "        text = []\n",
        "        for line in line_infos:\n",
        "            for word_metadata in line:\n",
        "                for i in range(len(word_metadata[\"words\"])):\n",
        "                    text.append(word_metadata[\"words\"][i]['text'])\n",
        "        return text\n",
        "    \n",
        "    def draw_bounding_boxes(self, word_infos, blob_url, filename):\n",
        "        name = os.path.basename(filename)\n",
        "        plt.figure(figsize=(50,50))\n",
        "        image = im = Image.open(requests.get(blob_url, stream=True).raw)\n",
        "        ax = plt.imshow(image, alpha=0.5)\n",
        "        for word in word_infos:\n",
        "            bbox = [int(num) for num in word[\"boundingBox\"].split(\",\")]\n",
        "            text = word[\"text\"]\n",
        "            origin = (bbox[0], bbox[1])\n",
        "            patch  = Rectangle(origin, bbox[2], bbox[3], fill=False, linewidth=2, color='y')\n",
        "            ax.axes.add_patch(patch)\n",
        "            plt.text(origin[0], origin[1], text, fontsize=20, weight=\"bold\", va=\"top\")\n",
        "        _ = plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "    \n",
        "    def __truncatechar(self, text,up_to= 5100):\n",
        "        _, text = os.path.split(text)\n",
        "        text = (text[:up_to] + '..') if len(text) > 5100 else text\n",
        "        return text\n",
        "                            \n",
        "    def detect_language(self, text):\n",
        "        language_api_url = self.__text_anaytics_url + \"languages\"\n",
        "        text = self.__truncatechar(text)\n",
        "        document = { 'documents': [\n",
        "            { 'id': '1', 'text': text }\n",
        "        ]}\n",
        "        response  = requests.post(language_api_url, headers=self.__headers, json=document)\n",
        "        languages = response.json()\n",
        "        language = languages['documents'][0]['detectedLanguages'][0][\"iso6391Name\"]\n",
        "        return language\n",
        "    \n",
        "    def translate(self, language, text,key,translate_to=\"es\"):\n",
        "        sentiment_api_url = self.__translate_url\n",
        "        params={\"from\":language,\"to\":translate_to}\n",
        "        text = self.__truncatechar(text,up_to=4900)\n",
        "        document = [{\"Text\": text}]\n",
        "        headers = dict(self.__headers)\n",
        "        headers['Ocp-Apim-Subscription-Key'] = key\n",
        "        response  = requests.post(sentiment_api_url, headers=headers, json=document,params=params)\n",
        "        translations = response.json()\n",
        "        return translations\n",
        "    \n",
        "    def get_entities(self, language, text):\n",
        "        text = self.__truncatechar(text,up_to=5000)\n",
        "        key_phrase_api_url =  self.__text_anaytics_url + \"entities\"\n",
        "        document = {'documents' : [{'id': '1', 'language': language, 'text': text}]}\n",
        "        response  = requests.post(key_phrase_api_url, headers=self.__headers, json=document)\n",
        "        key_phrases = response.json()\n",
        "        return key_phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "blob_base_url = \"https://eatraining3939401398.blob.core.windows.net/newspapers/\"\n",
        "image_list =[\"Boston1.jpg\",\"Boston2.jpg\",\"Boston3.jpg\",\"NewYorkTimes1.jpg\",\"NewYorkTimes2.jpg\",\"NewYorkTimes3.jpg\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.storage.blob import BlockBlobService\n",
        "import json\n",
        "\n",
        "cs = CognitiveServices(cs_base_url,cs_key,translate_url)     \n",
        "\n",
        "#Boston newspapers\n",
        "for image in image_list[:1]:\n",
        "    (filename, ext) = os.path.splitext(image)\n",
        "    vision = cs.computer_vision_api(f\"{blob_base_url}{image}\")\n",
        "    text, word_infos = cs.ocr(f\"{blob_base_url}{image}\", image, draw_image=True)\n",
        "    language = cs.detect_language(text)\n",
        "    translations = cs.translate(language, text,translate_key)\n",
        "    entities = cs.get_entities(language,text)\n",
        "    enrich_data = {}\n",
        "    enrich_data[\"Vision\"] = vision\n",
        "    enrich_data[\"OCR\"] = word_infos\n",
        "    enrich_data[\"OCRText\"] = text\n",
        "    enrich_data[\"Language\"] = {\"language\":language}\n",
        "    enrich_data[\"Translation\"] = translations\n",
        "    enrich_data[\"Entities\"] = entities\n",
        "\n",
        "    with open('data.json', 'w',encoding='utf-8') as f:\n",
        "        json.dump(enrich_data, f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python361064biteaworkshopcondaf8cbfb2932cd468ba33d464c32196cc7",
      "display_name": "Python 3.6.10 64-bit ('ea-workshop': conda)",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10-final",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
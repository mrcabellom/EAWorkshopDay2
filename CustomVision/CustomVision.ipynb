{
  "cells": [
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Custom vision \n",
        "\n",
        "### Inference example using tensorflow\n",
        "\n",
        "\n",
        "#### Initial Setup\n",
        "\n",
        "Once we have exported our tensorflow model from Custom vision portal, we are ready to load it using the tensorflow framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "print(tf.version)\n",
        "\n",
        "filename = 'models/model.pb'\n",
        "labels_filename = 'models/labels.txt'\n",
        "\n",
        "graph_def = tf.compat.v1.GraphDef()\n",
        "labels = []\n",
        "\n",
        "# Import the TF graph\n",
        "with tf.compat.v1.gfile.GFile(filename, 'rb') as f:\n",
        "    graph_def.ParseFromString(f.read())\n",
        "    tf.import_graph_def(graph_def, name='')\n",
        "\n",
        "# Create a list of labels.\n",
        "with open(labels_filename, 'rt') as lf:\n",
        "    for l in lf:\n",
        "        labels.append(l.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Inference script\n",
        "\n",
        "Once we have loaded the tensorflow graph of the model, we can use one of our tests images to develop our inference script. \n",
        "\n",
        "- Resize our image to fit the input size of our model.\n",
        "- Transpose the tensor from RGB color order to BGR.\n",
        "- Indentify the input node and the output layer from our graph. We can use the netron application to see our graph.\n",
        "- Obtain the max probability of our classification class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load from a file\n",
        "imageFile = \"images/test/test_image.jpg\"\n",
        "image = Image.open(imageFile)\n",
        "\n",
        "# Resize \n",
        "image = image.resize((224, 224), resample=Image.BILINEAR)\n",
        "\n",
        "# Convert to numpy array - tensor\n",
        "image_tensor = np.asarray(image)\n",
        "\n",
        "# Convert RGB -> BGR\n",
        "r,g,b = np.array(image_tensor).T\n",
        "image_tensor = np.array([b,g,r]).transpose()\n",
        "\n",
        "print(\"Numpy array mode=BGR shape={}\".format(image_tensor.shape))\n",
        "\n",
        "# These names are part of the model and cannot be changed.\n",
        "output_layer = 'loss:0'\n",
        "input_node = 'Placeholder:0'\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    prob_tensor = sess.graph.get_tensor_by_name(output_layer)\n",
        "    predictions, = sess.run(prob_tensor, {input_node: [image_tensor] })\n",
        "    \n",
        "print(f\"Predictions: {predictions}\")\n",
        "\n",
        "# Print the highest probability label\n",
        "highest_probability_index = np.argmax(predictions)\n",
        "print('Classified as: ' + labels[highest_probability_index])\n",
        "\n",
        "# Or you can print out all of the results mapping labels to probabilities.\n",
        "label_index = 0\n",
        "for p in predictions:\n",
        "    truncated_probablity = np.float64(np.round(p,4))\n",
        "    print(labels[label_index], truncated_probablity)\n",
        "    label_index += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python361064biteaworkshopcondaf8cbfb2932cd468ba33d464c32196cc7",
      "display_name": "Python 3.6.10 64-bit ('ea-workshop': conda)",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10-final",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}